{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % load_ext autoreload\n",
    "# % autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightkurve as lk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from patsy import dmatrix\n",
    "from lightkurve.correctors import DesignMatrix, DesignMatrixCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcf = lk.search_lightcurvefile('K2-50').download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = lcf.PDCSAP_FLUX.remove_nans().normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sff = lc.remove_nans().to_corrector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "clc = sff.correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = lk.correctors.RegressionCorrector(lc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%lprun` not found.\n"
     ]
    }
   ],
   "source": [
    "%lprun -f sff.X[0]._validate sff.X[0]._validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.matrix_rank(sff.X[0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sff.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(sff.X[0].values.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f r.correct r.correct(sff.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clc.errorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = lc.flatten(101).errorbar()\n",
    "clc.normalize().errorbar(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(lcf.PDCSAP_FLUX.remove_nans().normalize().flux_err, clc.flux_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_lc = sff.correct(centroid_col=centroid_col,\n",
    "                           centroid_row=centroid_row, windows=2, bins=5, restore_trend=True, cadence_mask=mask, breakindex=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = lc.plot(label='Raw')\n",
    "corrected_lc.plot(ax=ax, lw=2, label='lk.SFFCorrector')\n",
    "plt.plot(time, corrected_flux - np.median(corrected_flux) + 1, label='Vanderburg')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = 300\n",
    "raw_flux = data[:, 1][:n_points]\n",
    "centroid_col = data[:, 3][:n_points]\n",
    "centroid_row = data[:, 4][:n_points]\n",
    "\n",
    "time = np.concatenate((np.linspace(0, 20, int(n_points/3)),\n",
    "                       np.linspace(30, 78, int(n_points/3)),\n",
    "                       np.linspace(80, 100, int(n_points/3))\n",
    "                       ))\n",
    "lc = lk.KeplerLightCurve(time=time,\n",
    "                      flux=raw_flux,\n",
    "                      flux_err=np.ones(n_points) * 0.0001,\n",
    "                      centroid_col=centroid_col,\n",
    "                      centroid_row=centroid_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc.errorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lk.correctors.SFFCorrector(lc).correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isclose(corrected_flux, corrected_lc.flux, atol=0.5e-3).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tpf = lk.search_targetpixelfile('K2-43').download()\n",
    "lcf = lk.search_lightcurvefile('K2-43').download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spline_dm(x, n_knots=20, degree=3, name='spline', include_intercept=False):\n",
    "    spline_dm = np.asarray(dmatrix(\"bs(x, df={}, degree={}, include_intercept={}) - 1\".format(n_knots, degree, include_intercept), {\"x\": x}))\n",
    "    df = pd.DataFrame(spline_dm, columns=['knot{}'.format(idx + 1) for idx in range(n_knots)])\n",
    "    return DesignMatrix(df, name=name)\n",
    "\n",
    "def get_centroid_dm(c, r, name='centroids'):\n",
    "    arclength = ((c - c.min())**2 + (r - r.min())**2)**0.5\n",
    "\n",
    "    ar = [c, r,\n",
    "          c**2, r**2,\n",
    "          c**3, r**3,\n",
    "          c*r,\n",
    "          c**2*r, c*r**2, c**2*r**2]\n",
    "\n",
    "    columns = [r'col', r'row',\n",
    "               r'col^2', r'row^2',\n",
    "               r'col^3', r'row^3',\n",
    "               r'col \\times row', r'col^2 \\times row', r'col \\times row^2', r'col^2 \\times row^2']\n",
    "\n",
    "    df = pd.DataFrame(np.asarray(ar).T, columns=columns)\n",
    "    return DesignMatrix(df, name=name)\n",
    "\n",
    "def get_pixel_dm(pixels):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.modeling import models, fitting\n",
    "def _get_window_points(self, windows, arc, breakindex):\n",
    "        ''' Build window points, based on where thrusters are fired. '''\n",
    "\n",
    "        def _get_thruster_firings(arclength):\n",
    "            ''' Find locations where K2 fired thrusters\n",
    "            Parameters:\n",
    "            ----------\n",
    "            arc : np.ndarray\n",
    "                arclength as a function of time\n",
    "            Returns:\n",
    "            -------\n",
    "            thrusters: np.ndarray of bools\n",
    "                True at times where thrusters were fired.\n",
    "            '''\n",
    "            arc = np.copy(arclength)\n",
    "            # Rate of change of rate of change of arclength wrt time\n",
    "            d2adt2 = (np.gradient(np.gradient(arc)))\n",
    "            # Fit a nice Gaussian, most points lie in a tight region, thruster firings are outliers\n",
    "            g = models.Gaussian1D(amplitude=100, mean=0, stddev=0.01)\n",
    "            fitter = fitting.LevMarLSQFitter()\n",
    "            h = np.histogram(d2adt2[np.isfinite(d2adt2)], np.arange(-0.5, 0.5, 0.0001), density=True);\n",
    "            xbins = h[1][1:] - np.median(np.diff(h[1]))\n",
    "            g = fitter(g, xbins, h[0], weights=h[0]**0.5)\n",
    "\n",
    "            def _start_and_end(method):\n",
    "                ''' Find points at the start or end of a roll\n",
    "                '''\n",
    "                if method == 'start':\n",
    "                    thrusters = (d2adt2 < (g.stddev * -5)) & np.isfinite(d2adt2)\n",
    "                if method == 'end':\n",
    "                    thrusters = (d2adt2 > (g.stddev * 5)) & np.isfinite(d2adt2)\n",
    "                # Pick the best thruster in each cluster\n",
    "                idx = np.array_split(np.arange(len(thrusters)), np.where(np.gradient(np.asarray(thrusters, int)) == 0)[0])\n",
    "                m = np.array_split(thrusters, np.where(np.gradient(np.asarray(thrusters, int)) == 0)[0])\n",
    "                th = []\n",
    "                for jdx in range(len(idx)):\n",
    "                    if m[jdx].sum() == 0:\n",
    "                        th.append(m[jdx])\n",
    "                    else:\n",
    "                        th.append((np.abs(np.gradient(arc)[idx[jdx]]) == np.abs(np.gradient(arc)[idx[jdx]][m[jdx]]).max()) & m[jdx])\n",
    "                thrusters = np.hstack(th)\n",
    "                return thrusters\n",
    "\n",
    "            # Get the start and end points\n",
    "            thrusters = np.asarray([_start_and_end('start'), _start_and_end('end')])\n",
    "            thrusters = thrusters.any(axis=0)\n",
    "\n",
    "            # Take just the first point.\n",
    "            thrusters = (np.gradient(np.asarray(thrusters, int)) >= 0) & thrusters\n",
    "            return thrusters\n",
    "\n",
    "        thrusters = _get_thruster_firings(arc)\n",
    "        thrusters[breakindex] = True\n",
    "        thrusters = np.where(thrusters)[0]\n",
    "\n",
    "        if breakindex != 0:\n",
    "            window_points = np.append(np.linspace(0, breakindex + 1, windows//2 + 1, dtype=int)[1:],\n",
    "                                  np.linspace(breakindex + 1, len(arc), windows//2 + 1, dtype=int)[1:-1])\n",
    "            window_points[np.argmin((window_points - breakindex + 1)**2)] = breakindex + 1\n",
    "        else:\n",
    "            window_points = np.linspace(0, len(self.flux) + 1, windows)\n",
    "        window_points = [thrusters[np.argmin(np.abs(wp - thrusters))] + 1 for wp in window_points]\n",
    "\n",
    "        if window_points[0] < (np.median(np.diff(window_points)) * 0.4):\n",
    "            window_points = window_points[1:]\n",
    "        return window_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = lcf.PDCSAP_FLUX.remove_nans()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, r = lc.centroid_col - lc.centroid_col.mean(), lc.centroid_row  - lc.centroid_row.mean()\n",
    "arclength = ((c - c.min())**2 + (r - r.min())**2)**0.5\n",
    "dm = lk.correctors.DesignMatrixCollection([get_centroid_dm(c, r).append_constant().split(1753), get_spline_dm(lc.time, n_knots=80)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = lk.correctors.RegressionCorrector(lc, dm)\n",
    "r.correct(niters=5)\n",
    "r.diagnose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_sff_dm(lc, breakindex=1753, windows=5, bins=5, n_knots=80):\n",
    "#     c, r = lc.centroid_col - lc.centroid_col.mean(), lc.centroid_row  - lc.centroid_row.mean()\n",
    "#     arclength = ((c - c.min())**2 + (r - r.min())**2)**0.5\n",
    "\n",
    "#     # centroids\n",
    "#     c_dm = get_centroid_dm(c, r).split(1753).whiten()\n",
    "\n",
    "#     # long term\n",
    "#     lt_dm = get_spline_dm(lc.time, n_knots=n_knots, include_intercept=True)\n",
    "\n",
    "#     # sff\n",
    "#     window_points = _get_window_points(lc, windows, arclength, breakindex)\n",
    "#     sff_dm = get_spline_dm(arclength, n_knots=bins, name='arclength', degree=3, include_intercept=True)\n",
    "    \n",
    "    \n",
    "#     return DesignMatrixCollection([lt_dm, sff_dm.split(window_points)]), window_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = 20\n",
    "bins = 5\n",
    "degree = 3\n",
    "include_intercept=False\n",
    "breakindex=1753\n",
    "wp = _get_window_points(lc, windows, arclength, breakindex)\n",
    "\n",
    "\n",
    "lower_idx = np.append(0, wp)\n",
    "upper_idx = np.append(wp, len(lc.time))\n",
    "\n",
    "stack = []\n",
    "columns = []\n",
    "for idx, a, b in zip(range(len(lower_idx)), lower_idx, upper_idx):\n",
    "    #knots = list(np.linspace(*np.percentile(arclength[a:b], [5, 95]), bins))\n",
    "    knots = list(np.percentile(arclength[a:b], np.linspace(0, 100, bins+1)[1:-1]))\n",
    "    ar = np.copy(arclength)\n",
    "    ar[~np.in1d(ar, ar[a:b])] = -1\n",
    "    dm = np.asarray(dmatrix(\"bs(x, knots={}, degree={}, include_intercept={}) - 1\".format(knots, degree, include_intercept), {\"x\": ar}))\n",
    "    stack.append(dm)\n",
    "    columns.append(['window{}_bin{}'.format(idx+1, jdx+1) for jdx in range(len(dm.T))])\n",
    "\n",
    "\n",
    "sff_dm = DesignMatrix(pd.DataFrame(np.hstack(stack), columns=np.hstack(columns)), name='arclength')\n",
    "\n",
    "# long term\n",
    "s_dm = get_spline_dm(lc.time, n_knots=100, include_intercept=True)\n",
    "\n",
    "\n",
    "#c_dm = DesignMatrix(pd.DataFrame(np.asarray([lc.centroid_col, lc.centroid_row]).T, columns=['col', 'row']), name='c')\n",
    "c_dm = get_centroid_dm(lc.centroid_col, lc.centroid_row)\n",
    "dm = DesignMatrixCollection([c_dm, s_dm.append_constant(), sff_dm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = lk.correctors.RegressionCorrector(lc, dm)\n",
    "r.correct(niters=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.corrected_lc.estimate_cdpp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.diagnose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.diagnostic_lightcurves['spline'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower_idx = np.append(0, wp)\n",
    "# upper_idx = np.append(wp, len(lc.time))\n",
    "# f = (lc.flux - r.diagnostic_lightcurves['spline'].flux)\n",
    "# m = r.diagnostic_lightcurves['arclength'].flux\n",
    "\n",
    "# for a, b in zip(lower_idx, upper_idx):\n",
    "#     #plt.figure()\n",
    "#     plt.scatter(arclength[a:b], f[a:b], s=1)\n",
    "#     plt.scatter(arclength[a:b][~r.cadence_mask[a:b]], f[a:b][~r.cadence_mask[a:b]], s=10, marker='x')\n",
    "\n",
    "#     s = np.argsort(arclength[a:b])\n",
    "#     plt.plot(arclength[a:b][s], (m[a:b] - np.median(m[a:b]) + np.median(f[a:b]))[s])\n",
    "#     plt.xlabel('Arclength')\n",
    "#     plt.ylabel('Flux')\n",
    "#     #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# lower_idx = np.append(0, wp)\n",
    "# upper_idx = np.append(wp, len(lc.time))\n",
    "# f = (lc.flux - r.diagnostic_lightcurves['spline'].flux)\n",
    "# m = r.diagnostic_lightcurves['arclength'].flux\n",
    "\n",
    "# for a, b in zip(lower_idx, upper_idx):\n",
    "#     plt.figure()\n",
    "#     plt.scatter(arclength[a:b], f[a:b], c='k', s=1)\n",
    "#     plt.scatter(arclength[a:b][~r.cadence_mask[a:b]], f[a:b][~r.cadence_mask[a:b]], c='r', s=10, marker='x')\n",
    "\n",
    "#     s = np.argsort(arclength[a:b])\n",
    "#     plt.plot(arclength[a:b][s], (m[a:b] - np.median(m[a:b]) + np.median(f[a:b]))[s], c='b')\n",
    "#     plt.xlabel('Arclength')\n",
    "#     plt.ylabel('Flux')\n",
    "#     #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(arclength, lc.flux - r.diagnostic_lightcurves['spline'].flux, s=1, c='k')\n",
    "plt.scatter(arclength, lc.flux - r.diagnostic_lightcurves['spline'].flux, s=1, c='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.X.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.hstack([d.columns for d in dm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
